"""Benchmark index build and cache load performance."""

from __future__ import annotations

import json
import sys
from datetime import datetime, timezone
from pathlib import Path
from time import perf_counter
from typing import Iterable
from uuid import uuid4

ROOT = Path(__file__).resolve().parents[1]
PYTHON_SRC = ROOT / "python" / "src"
if str(PYTHON_SRC) not in sys.path:
    sys.path.insert(0, str(PYTHON_SRC))

from taskulus.cache import collect_issue_file_mtimes, load_cache_if_valid, write_cache
from taskulus.index import build_index_from_directory
from taskulus.issue_files import write_issue_to_file
from taskulus.models import DependencyLink, IssueData

ISSUE_COUNT = 1000
PYTHON_INDEX_BUILD_TARGET_MS = 50.0
PYTHON_CACHE_LOAD_TARGET_MS = 50.0


def create_issue(identifier: str, now: datetime) -> IssueData:
    """Create an IssueData instance for benchmarking."""
    dependencies = []
    if identifier.endswith("0"):
        dependencies = [
            DependencyLink(target="tsk-000001", type="blocked-by")
        ]
    return IssueData(
        id=identifier,
        title=f"Benchmark issue {identifier}",
        type="task",
        status="open",
        priority=2,
        assignee=None,
        creator=None,
        parent=None,
        labels=["benchmark"],
        dependencies=dependencies,
        comments=[],
        description="",
        created_at=now,
        updated_at=now,
        closed_at=None,
        custom={},
    )


def generate_issues(issues_directory: Path, identifiers: Iterable[str]) -> None:
    """Generate issue JSON files for benchmarking."""
    now = datetime.now(timezone.utc)
    issues_directory.mkdir(parents=True, exist_ok=True)
    for identifier in identifiers:
        issue = create_issue(identifier, now)
        write_issue_to_file(issue, issues_directory / f"{identifier}.json")


def run_benchmark() -> None:
    """Run index build and cache load benchmarks."""
    temp_root = Path(
        Path.cwd() / "tools" / "tmp" / f"index-benchmark-{uuid4().hex}"
    )
    issues_directory = temp_root / "project" / "issues"
    cache_path = temp_root / "project" / ".cache" / "index.json"

    identifiers = [f"tsk-{i:06d}" for i in range(ISSUE_COUNT)]
    generate_issues(issues_directory, identifiers)

    start = perf_counter()
    index = build_index_from_directory(issues_directory)
    build_seconds = perf_counter() - start
    build_ms = build_seconds * 1000.0

    mtimes = collect_issue_file_mtimes(issues_directory)
    write_cache(index, cache_path, mtimes)

    start = perf_counter()
    cached = load_cache_if_valid(cache_path, issues_directory)
    cache_seconds = perf_counter() - start
    cache_ms = cache_seconds * 1000.0

    if cached is None:
        raise RuntimeError("cache did not load")

    results = {
        "issue_count": ISSUE_COUNT,
        "build_ms": build_ms,
        "cache_load_ms": cache_ms,
        "build_target_ms": PYTHON_INDEX_BUILD_TARGET_MS,
        "cache_load_target_ms": PYTHON_CACHE_LOAD_TARGET_MS,
    }
    print(json.dumps(results, indent=2, sort_keys=True))


if __name__ == "__main__":
    run_benchmark()
